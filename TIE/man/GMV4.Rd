% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/estim_functions.R
\name{GMV4}
\alias{GMV4}
\title{Gomes, Miranda, and Viseu (Statistica Neerlandica) Jackknife Estimator - Type 2}
\usage{
GMV4(X, k, eps)
}
\arguments{
\item{X}{A numeric vector containing the data sample.}

\item{k}{An optional integer specifying the number of top-order statistics to use. Defaults to the square root of the sample size.}

\item{eps}{An optional numeric parameter specifying the maximum error tolerance for calculating the optimal \(\alpha\). Defaults to \code{1e-8}.}
}
\value{
A numeric value representing the estimated tail index.
}
\description{
Computes the Jackknife tail index estimator from Gomes, Miranda, and Viseu (Statistica Neerlandica, equation 27, page 11).
}
\details{
This estimator refines the tail index by iteratively solving for the optimal parameter \(\alpha\) and using it in a weighted Jackknife formula:
- The auxiliary parameter \(\rho\) is calculated using the \code{rho} function with \( k \cdot 1.1 \) or \( 0.9 \cdot n \) order statistics, whichever is smaller.
- The optimal \(\alpha\) is determined by solving the equation:
  \[
  T = 3\alpha^3 - 5\alpha^2 + \alpha \cdot (r^2 - r + 3) - (2r^2 - 2r + 1) = 0,
  \]
  using a binary search approach with a tolerance of \code{eps}.
- Two generalized estimators are computed:
  - \( g_1 \): The generalized estimator using \(\text{GMV1}\) with the optimal \(\alpha\).
  - \( g_2 \): The generalized estimator using \(\text{GMV2}\) with the optimal \(\alpha\).
- The tail index is then calculated as:
  \[
  \text{Tail Index} = \frac{r}{\alpha \cdot g_1 - (\alpha - r) \cdot g_2}.
  \]

This method combines iterative optimization and weighting schemes to improve bias reduction.
}
\examples{
set.seed(123)
n = 1000
x = (abs(stats::rcauchy(n)))^(2)
GMV4(x)

}
